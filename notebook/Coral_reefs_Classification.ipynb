{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "AtkTewlDY6En",
        "outputId": "00560bf0-f144-4c80-84a0-aef8ae2fd331"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5f781314-0593-48e7-a95f-f1f3e71f49b4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5f781314-0593-48e7-a95f-f1f3e71f49b4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Dataset URL: https://www.kaggle.com/datasets/asfarhossainsitab/coral-reefs-images\n",
            "License(s): apache-2.0\n",
            "Downloading coral-reefs-images.zip to /content\n",
            " 95% 674M/711M [00:03<00:00, 139MB/s] \n",
            "100% 711M/711M [00:03<00:00, 213MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Step 1 â€” Upload your Kaggle API key (kaggle.json)\n",
        "from google.colab import files\n",
        "files.upload()  # ğŸ‘‰ Upload kaggle.json from your local system\n",
        "# Step 2 â€” Move kaggle.json to the correct folder and set permissions\n",
        "!mkdir -p ~/.kaggle \n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "# Step 3 â€” Download the Coral Reefs Images dataset from Kaggle\n",
        "!kaggle datasets download -d asfarhossainsitab/coral-reefs-images\n",
        "# Step 4 â€” Unzip the dataset into a working directory\n",
        "!unzip -q coral-reefs-images.zip -d ./coral_reef_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqVe2WN0ZW80",
        "outputId": "49d78c13-9c1e-4d24-83b3-909407603087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow matplotlib scikit-learn opencv-python pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiillEquZeLJ"
      },
      "outputs": [],
      "source": [
        "# coral_classifier_with_gradcam.py\n",
        "# Python 3.8+, TensorFlow 2.x\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import cv2\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "szH1KcBBoC_W",
        "outputId": "37f54307-6d4a-406e-b579-b77b99fb0925"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 9662 images belonging to 2 classes.\n",
            "Found 463 images belonging to 2 classes.\n",
            "Classes: ['Bleached', 'Healthy']\n",
            "Class indices: {'Bleached': 0, 'Healthy': 1}\n",
            "Creating ResNet50 model...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\n",
            "Model Summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2d        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     â”‚    \u001b[38;5;34m23,587,712\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2d        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           â”‚         \u001b[38;5;34m8,192\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚       \u001b[38;5;34m524,544\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚        \u001b[38;5;34m32,896\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m129\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,153,473</span> (92.14 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,153,473\u001b[0m (92.14 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">561,665</span> (2.14 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m561,665\u001b[0m (2.14 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,591,808</span> (90.00 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,591,808\u001b[0m (90.00 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Phase 1: Training with frozen base model\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516ms/step - accuracy: 0.5808 - loss: 0.6792 - precision: 0.6029 - recall: 0.4397\n",
            "Epoch 1: val_accuracy improved from -inf to 0.64795, saving model to coral_reef_resnet50_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 552ms/step - accuracy: 0.5810 - loss: 0.6791 - precision: 0.6029 - recall: 0.4400 - val_accuracy: 0.6479 - val_loss: 0.6301 - val_precision: 0.6974 - val_recall: 0.4753 - learning_rate: 1.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - accuracy: 0.6711 - loss: 0.6039 - precision: 0.6730 - recall: 0.6314\n",
            "Epoch 2: val_accuracy improved from 0.64795 to 0.73002, saving model to coral_reef_resnet50_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 494ms/step - accuracy: 0.6712 - loss: 0.6038 - precision: 0.6730 - recall: 0.6315 - val_accuracy: 0.7300 - val_loss: 0.5318 - val_precision: 0.7207 - val_recall: 0.7175 - learning_rate: 1.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - accuracy: 0.7263 - loss: 0.5480 - precision: 0.7270 - recall: 0.7140\n",
            "Epoch 3: val_accuracy improved from 0.73002 to 0.77538, saving model to coral_reef_resnet50_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 495ms/step - accuracy: 0.7264 - loss: 0.5479 - precision: 0.7270 - recall: 0.7140 - val_accuracy: 0.7754 - val_loss: 0.4726 - val_precision: 0.8083 - val_recall: 0.6996 - learning_rate: 1.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - accuracy: 0.7589 - loss: 0.4964 - precision: 0.7584 - recall: 0.7308\n",
            "Epoch 4: val_accuracy improved from 0.77538 to 0.79698, saving model to coral_reef_resnet50_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 495ms/step - accuracy: 0.7589 - loss: 0.4964 - precision: 0.7584 - recall: 0.7308 - val_accuracy: 0.7970 - val_loss: 0.4374 - val_precision: 0.8086 - val_recall: 0.7578 - learning_rate: 1.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - accuracy: 0.7801 - loss: 0.4670 - precision: 0.7817 - recall: 0.7552\n",
            "Epoch 5: val_accuracy improved from 0.79698 to 0.83153, saving model to coral_reef_resnet50_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 505ms/step - accuracy: 0.7801 - loss: 0.4670 - precision: 0.7817 - recall: 0.7552 - val_accuracy: 0.8315 - val_loss: 0.4030 - val_precision: 0.8436 - val_recall: 0.7982 - learning_rate: 1.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - accuracy: 0.7820 - loss: 0.4647 - precision: 0.7864 - recall: 0.7660\n",
            "Epoch 6: val_accuracy did not improve from 0.83153\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 483ms/step - accuracy: 0.7820 - loss: 0.4647 - precision: 0.7864 - recall: 0.7660 - val_accuracy: 0.8315 - val_loss: 0.4052 - val_precision: 0.8680 - val_recall: 0.7668 - learning_rate: 1.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - accuracy: 0.7991 - loss: 0.4463 - precision: 0.8091 - recall: 0.7746\n",
            "Epoch 7: val_accuracy did not improve from 0.83153\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 489ms/step - accuracy: 0.7991 - loss: 0.4463 - precision: 0.8090 - recall: 0.7746 - val_accuracy: 0.8315 - val_loss: 0.3863 - val_precision: 0.8311 - val_recall: 0.8161 - learning_rate: 1.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step - accuracy: 0.8004 - loss: 0.4323 - precision: 0.8088 - recall: 0.7742\n",
            "Epoch 8: val_accuracy did not improve from 0.83153\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 489ms/step - accuracy: 0.8004 - loss: 0.4323 - precision: 0.8088 - recall: 0.7742 - val_accuracy: 0.8315 - val_loss: 0.4015 - val_precision: 0.8251 - val_recall: 0.8251 - learning_rate: 1.0000e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step - accuracy: 0.8011 - loss: 0.4308 - precision: 0.8079 - recall: 0.7790\n",
            "Epoch 9: val_accuracy improved from 0.83153 to 0.83801, saving model to coral_reef_resnet50_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 492ms/step - accuracy: 0.8012 - loss: 0.4307 - precision: 0.8079 - recall: 0.7790 - val_accuracy: 0.8380 - val_loss: 0.3928 - val_precision: 0.8558 - val_recall: 0.7982 - learning_rate: 1.0000e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - accuracy: 0.8124 - loss: 0.4075 - precision: 0.8178 - recall: 0.7847\n",
            "Epoch 10: val_accuracy did not improve from 0.83801\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 490ms/step - accuracy: 0.8124 - loss: 0.4075 - precision: 0.8179 - recall: 0.7847 - val_accuracy: 0.8164 - val_loss: 0.3957 - val_precision: 0.8224 - val_recall: 0.7892 - learning_rate: 1.0000e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - accuracy: 0.8126 - loss: 0.4069 - precision: 0.8236 - recall: 0.7873\n",
            "Epoch 11: val_accuracy did not improve from 0.83801\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 490ms/step - accuracy: 0.8126 - loss: 0.4069 - precision: 0.8236 - recall: 0.7873 - val_accuracy: 0.8251 - val_loss: 0.3951 - val_precision: 0.8447 - val_recall: 0.7803 - learning_rate: 1.0000e-04\n",
            "Epoch 12/15\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - accuracy: 0.8232 - loss: 0.3983 - precision: 0.8297 - recall: 0.7932\n",
            "Epoch 12: val_accuracy improved from 0.83801 to 0.84449, saving model to coral_reef_resnet50_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 487ms/step - accuracy: 0.8232 - loss: 0.3983 - precision: 0.8297 - recall: 0.7932 - val_accuracy: 0.8445 - val_loss: 0.3796 - val_precision: 0.8756 - val_recall: 0.7892 - learning_rate: 1.0000e-04\n",
            "Epoch 13/15\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step - accuracy: 0.8156 - loss: 0.3923 - precision: 0.8233 - recall: 0.7837\n",
            "Epoch 13: val_accuracy improved from 0.84449 to 0.85313, saving model to coral_reef_resnet50_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 491ms/step - accuracy: 0.8156 - loss: 0.3923 - precision: 0.8233 - recall: 0.7838 - val_accuracy: 0.8531 - val_loss: 0.3712 - val_precision: 0.8744 - val_recall: 0.8117 - learning_rate: 1.0000e-04\n",
            "Epoch 14/15\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step - accuracy: 0.8264 - loss: 0.3907 - precision: 0.8359 - recall: 0.7958\n",
            "Epoch 14: val_accuracy did not improve from 0.85313\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 486ms/step - accuracy: 0.8264 - loss: 0.3907 - precision: 0.8359 - recall: 0.7959 - val_accuracy: 0.8380 - val_loss: 0.3868 - val_precision: 0.8458 - val_recall: 0.8117 - learning_rate: 1.0000e-04\n",
            "Epoch 15/15\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step - accuracy: 0.8284 - loss: 0.3856 - precision: 0.8335 - recall: 0.8126\n",
            "Epoch 15: val_accuracy did not improve from 0.85313\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 489ms/step - accuracy: 0.8284 - loss: 0.3856 - precision: 0.8335 - recall: 0.8125 - val_accuracy: 0.8445 - val_loss: 0.3806 - val_precision: 0.8416 - val_recall: 0.8341 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 13.\n",
            "\n",
            "==================================================\n",
            "Phase 2: Fine-tuning - Unfreezing top layers\n",
            "==================================================\n",
            "\n",
            "Epoch 15/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528ms/step - accuracy: 0.6492 - loss: 1.2791 - precision_1: 0.6409 - recall_1: 0.6138\n",
            "Epoch 15: val_accuracy did not improve from 0.85313\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 558ms/step - accuracy: 0.6493 - loss: 1.2784 - precision_1: 0.6411 - recall_1: 0.6139 - val_accuracy: 0.7516 - val_loss: 0.6079 - val_precision_1: 0.8649 - val_recall_1: 0.5740 - learning_rate: 1.0000e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.7332 - loss: 0.8200 - precision_1: 0.7304 - recall_1: 0.7037\n",
            "Epoch 16: val_accuracy did not improve from 0.85313\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 496ms/step - accuracy: 0.7332 - loss: 0.8198 - precision_1: 0.7304 - recall_1: 0.7037 - val_accuracy: 0.7624 - val_loss: 0.8517 - val_precision_1: 0.8693 - val_recall_1: 0.5964 - learning_rate: 1.0000e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - accuracy: 0.7652 - loss: 0.6896 - precision_1: 0.7577 - recall_1: 0.7452\n",
            "Epoch 17: val_accuracy did not improve from 0.85313\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 496ms/step - accuracy: 0.7652 - loss: 0.6895 - precision_1: 0.7578 - recall_1: 0.7452 - val_accuracy: 0.7408 - val_loss: 0.9281 - val_precision_1: 0.9640 - val_recall_1: 0.4798 - learning_rate: 1.0000e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - accuracy: 0.7842 - loss: 0.6191 - precision_1: 0.7846 - recall_1: 0.7652\n",
            "Epoch 18: val_accuracy did not improve from 0.85313\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 500ms/step - accuracy: 0.7842 - loss: 0.6189 - precision_1: 0.7846 - recall_1: 0.7652 - val_accuracy: 0.8143 - val_loss: 0.6026 - val_precision_1: 0.8870 - val_recall_1: 0.7040 - learning_rate: 1.0000e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.8002 - loss: 0.5397 - precision_1: 0.8016 - recall_1: 0.7821\n",
            "Epoch 19: val_accuracy did not improve from 0.85313\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 500ms/step - accuracy: 0.8003 - loss: 0.5397 - precision_1: 0.8017 - recall_1: 0.7821 - val_accuracy: 0.8337 - val_loss: 0.4584 - val_precision_1: 0.8288 - val_recall_1: 0.8251 - learning_rate: 1.0000e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501ms/step - accuracy: 0.8074 - loss: 0.5117 - precision_1: 0.8148 - recall_1: 0.7836\n",
            "Epoch 20: val_accuracy did not improve from 0.85313\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 507ms/step - accuracy: 0.8074 - loss: 0.5117 - precision_1: 0.8148 - recall_1: 0.7836 - val_accuracy: 0.7754 - val_loss: 0.5156 - val_precision_1: 0.8889 - val_recall_1: 0.6099 - learning_rate: 1.0000e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step - accuracy: 0.8195 - loss: 0.4710 - precision_1: 0.8236 - recall_1: 0.7958\n",
            "Epoch 21: val_accuracy did not improve from 0.85313\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 504ms/step - accuracy: 0.8195 - loss: 0.4709 - precision_1: 0.8237 - recall_1: 0.7958 - val_accuracy: 0.8143 - val_loss: 0.5638 - val_precision_1: 0.8960 - val_recall_1: 0.6951 - learning_rate: 1.0000e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step - accuracy: 0.8206 - loss: 0.4626 - precision_1: 0.8221 - recall_1: 0.8059\n",
            "Epoch 22: val_accuracy did not improve from 0.85313\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 502ms/step - accuracy: 0.8206 - loss: 0.4626 - precision_1: 0.8221 - recall_1: 0.8059 - val_accuracy: 0.6371 - val_loss: 1.5056 - val_precision_1: 0.5718 - val_recall_1: 0.9821 - learning_rate: 1.0000e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - accuracy: 0.8278 - loss: 0.4359 - precision_1: 0.8319 - recall_1: 0.8069\n",
            "Epoch 23: val_accuracy did not improve from 0.85313\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 493ms/step - accuracy: 0.8278 - loss: 0.4359 - precision_1: 0.8319 - recall_1: 0.8069 - val_accuracy: 0.8186 - val_loss: 0.5415 - val_precision_1: 0.9427 - val_recall_1: 0.6637 - learning_rate: 1.0000e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step - accuracy: 0.8354 - loss: 0.4168 - precision_1: 0.8484 - recall_1: 0.8094\n",
            "Epoch 24: val_accuracy did not improve from 0.85313\n",
            "\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 504ms/step - accuracy: 0.8354 - loss: 0.4167 - precision_1: 0.8484 - recall_1: 0.8094 - val_accuracy: 0.6458 - val_loss: 1.5624 - val_precision_1: 0.5770 - val_recall_1: 0.9910 - learning_rate: 1.0000e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step - accuracy: 0.8551 - loss: 0.3598 - precision_1: 0.8587 - recall_1: 0.8412\n",
            "Epoch 25: val_accuracy improved from 0.85313 to 0.86177, saving model to coral_reef_resnet50_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 506ms/step - accuracy: 0.8551 - loss: 0.3597 - precision_1: 0.8587 - recall_1: 0.8412 - val_accuracy: 0.8618 - val_loss: 0.3678 - val_precision_1: 0.8245 - val_recall_1: 0.9058 - learning_rate: 5.0000e-06\n",
            "Epoch 26/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.8574 - loss: 0.3686 - precision_1: 0.8620 - recall_1: 0.8342\n",
            "Epoch 26: val_accuracy did not improve from 0.86177\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 495ms/step - accuracy: 0.8574 - loss: 0.3686 - precision_1: 0.8620 - recall_1: 0.8342 - val_accuracy: 0.8596 - val_loss: 0.3839 - val_precision_1: 0.8376 - val_recall_1: 0.8789 - learning_rate: 5.0000e-06\n",
            "Epoch 27/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.8600 - loss: 0.3408 - precision_1: 0.8718 - recall_1: 0.8349\n",
            "Epoch 27: val_accuracy did not improve from 0.86177\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 495ms/step - accuracy: 0.8600 - loss: 0.3408 - precision_1: 0.8718 - recall_1: 0.8349 - val_accuracy: 0.8423 - val_loss: 0.4012 - val_precision_1: 0.9213 - val_recall_1: 0.7354 - learning_rate: 5.0000e-06\n",
            "Epoch 28/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step - accuracy: 0.8728 - loss: 0.3112 - precision_1: 0.8871 - recall_1: 0.8505\n",
            "Epoch 28: val_accuracy improved from 0.86177 to 0.86393, saving model to coral_reef_resnet50_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 505ms/step - accuracy: 0.8728 - loss: 0.3113 - precision_1: 0.8871 - recall_1: 0.8505 - val_accuracy: 0.8639 - val_loss: 0.4151 - val_precision_1: 0.8101 - val_recall_1: 0.9372 - learning_rate: 5.0000e-06\n",
            "Epoch 29/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step - accuracy: 0.8654 - loss: 0.3359 - precision_1: 0.8716 - recall_1: 0.8463\n",
            "Epoch 29: val_accuracy improved from 0.86393 to 0.87041, saving model to coral_reef_resnet50_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 496ms/step - accuracy: 0.8654 - loss: 0.3359 - precision_1: 0.8716 - recall_1: 0.8463 - val_accuracy: 0.8704 - val_loss: 0.3860 - val_precision_1: 0.8655 - val_recall_1: 0.8655 - learning_rate: 5.0000e-06\n",
            "Epoch 30/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - accuracy: 0.8634 - loss: 0.3323 - precision_1: 0.8656 - recall_1: 0.8498\n",
            "Epoch 30: val_accuracy did not improve from 0.87041\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 492ms/step - accuracy: 0.8634 - loss: 0.3323 - precision_1: 0.8657 - recall_1: 0.8498 - val_accuracy: 0.8704 - val_loss: 0.3400 - val_precision_1: 0.8976 - val_recall_1: 0.8251 - learning_rate: 5.0000e-06\n",
            "Epoch 31/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step - accuracy: 0.8798 - loss: 0.3116 - precision_1: 0.8908 - recall_1: 0.8580\n",
            "Epoch 31: val_accuracy did not improve from 0.87041\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 503ms/step - accuracy: 0.8798 - loss: 0.3116 - precision_1: 0.8908 - recall_1: 0.8580 - val_accuracy: 0.7041 - val_loss: 0.8334 - val_precision_1: 0.9778 - val_recall_1: 0.3946 - learning_rate: 5.0000e-06\n",
            "Epoch 32/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - accuracy: 0.8684 - loss: 0.3199 - precision_1: 0.8741 - recall_1: 0.8476\n",
            "Epoch 32: val_accuracy did not improve from 0.87041\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 498ms/step - accuracy: 0.8684 - loss: 0.3198 - precision_1: 0.8741 - recall_1: 0.8476 - val_accuracy: 0.8683 - val_loss: 0.4194 - val_precision_1: 0.8214 - val_recall_1: 0.9283 - learning_rate: 5.0000e-06\n",
            "Epoch 33/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step - accuracy: 0.8735 - loss: 0.3230 - precision_1: 0.8804 - recall_1: 0.8534\n",
            "Epoch 33: val_accuracy did not improve from 0.87041\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 491ms/step - accuracy: 0.8734 - loss: 0.3230 - precision_1: 0.8804 - recall_1: 0.8534 - val_accuracy: 0.8531 - val_loss: 0.4585 - val_precision_1: 0.8112 - val_recall_1: 0.9058 - learning_rate: 5.0000e-06\n",
            "Epoch 34/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - accuracy: 0.8721 - loss: 0.3237 - precision_1: 0.8791 - recall_1: 0.8491\n",
            "Epoch 34: val_accuracy improved from 0.87041 to 0.88121, saving model to coral_reef_resnet50_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 503ms/step - accuracy: 0.8721 - loss: 0.3237 - precision_1: 0.8791 - recall_1: 0.8491 - val_accuracy: 0.8812 - val_loss: 0.3258 - val_precision_1: 0.9242 - val_recall_1: 0.8206 - learning_rate: 5.0000e-06\n",
            "Epoch 35/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - accuracy: 0.8808 - loss: 0.3002 - precision_1: 0.8892 - recall_1: 0.8616\n",
            "Epoch 35: val_accuracy did not improve from 0.88121\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 505ms/step - accuracy: 0.8808 - loss: 0.3002 - precision_1: 0.8892 - recall_1: 0.8616 - val_accuracy: 0.8423 - val_loss: 0.3878 - val_precision_1: 0.9310 - val_recall_1: 0.7265 - learning_rate: 5.0000e-06\n",
            "Epoch 36/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - accuracy: 0.8829 - loss: 0.2981 - precision_1: 0.8942 - recall_1: 0.8637\n",
            "Epoch 36: val_accuracy did not improve from 0.88121\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 506ms/step - accuracy: 0.8829 - loss: 0.2981 - precision_1: 0.8942 - recall_1: 0.8637 - val_accuracy: 0.8510 - val_loss: 0.4405 - val_precision_1: 0.9425 - val_recall_1: 0.7354 - learning_rate: 5.0000e-06\n",
            "Epoch 37/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - accuracy: 0.8655 - loss: 0.3152 - precision_1: 0.8864 - recall_1: 0.8346\n",
            "Epoch 37: val_accuracy did not improve from 0.88121\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 505ms/step - accuracy: 0.8655 - loss: 0.3152 - precision_1: 0.8863 - recall_1: 0.8347 - val_accuracy: 0.8121 - val_loss: 0.6342 - val_precision_1: 0.7361 - val_recall_1: 0.9507 - learning_rate: 5.0000e-06\n",
            "Epoch 38/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505ms/step - accuracy: 0.8840 - loss: 0.2894 - precision_1: 0.8943 - recall_1: 0.8607\n",
            "Epoch 38: val_accuracy did not improve from 0.88121\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 511ms/step - accuracy: 0.8840 - loss: 0.2894 - precision_1: 0.8943 - recall_1: 0.8607 - val_accuracy: 0.7214 - val_loss: 0.9392 - val_precision_1: 0.9796 - val_recall_1: 0.4305 - learning_rate: 5.0000e-06\n",
            "Epoch 39/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505ms/step - accuracy: 0.8899 - loss: 0.2763 - precision_1: 0.9018 - recall_1: 0.8700\n",
            "Epoch 39: val_accuracy improved from 0.88121 to 0.89633, saving model to coral_reef_resnet50_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 513ms/step - accuracy: 0.8899 - loss: 0.2763 - precision_1: 0.9018 - recall_1: 0.8700 - val_accuracy: 0.8963 - val_loss: 0.3403 - val_precision_1: 0.8788 - val_recall_1: 0.9103 - learning_rate: 5.0000e-06\n",
            "Epoch 40/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - accuracy: 0.8891 - loss: 0.2655 - precision_1: 0.8954 - recall_1: 0.8714\n",
            "Epoch 40: val_accuracy improved from 0.89633 to 0.90065, saving model to coral_reef_resnet50_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 538ms/step - accuracy: 0.8891 - loss: 0.2655 - precision_1: 0.8954 - recall_1: 0.8714 - val_accuracy: 0.9006 - val_loss: 0.3690 - val_precision_1: 0.8672 - val_recall_1: 0.9372 - learning_rate: 2.5000e-06\n",
            "Epoch 41/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - accuracy: 0.8934 - loss: 0.2768 - precision_1: 0.8993 - recall_1: 0.8754\n",
            "Epoch 41: val_accuracy did not improve from 0.90065\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 514ms/step - accuracy: 0.8934 - loss: 0.2768 - precision_1: 0.8993 - recall_1: 0.8753 - val_accuracy: 0.8855 - val_loss: 0.3208 - val_precision_1: 0.9126 - val_recall_1: 0.8430 - learning_rate: 2.5000e-06\n",
            "Epoch 42/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - accuracy: 0.8843 - loss: 0.2824 - precision_1: 0.8925 - recall_1: 0.8675\n",
            "Epoch 42: val_accuracy did not improve from 0.90065\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 506ms/step - accuracy: 0.8843 - loss: 0.2824 - precision_1: 0.8925 - recall_1: 0.8675 - val_accuracy: 0.8704 - val_loss: 0.3268 - val_precision_1: 0.8791 - val_recall_1: 0.8475 - learning_rate: 2.5000e-06\n",
            "Epoch 43/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509ms/step - accuracy: 0.8825 - loss: 0.2824 - precision_1: 0.8854 - recall_1: 0.8687\n",
            "Epoch 43: val_accuracy did not improve from 0.90065\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 516ms/step - accuracy: 0.8825 - loss: 0.2823 - precision_1: 0.8854 - recall_1: 0.8687 - val_accuracy: 0.8402 - val_loss: 0.4260 - val_precision_1: 0.9357 - val_recall_1: 0.7175 - learning_rate: 2.5000e-06\n",
            "Epoch 44/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - accuracy: 0.8978 - loss: 0.2513 - precision_1: 0.9023 - recall_1: 0.8842\n",
            "Epoch 44: val_accuracy did not improve from 0.90065\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 512ms/step - accuracy: 0.8978 - loss: 0.2513 - precision_1: 0.9023 - recall_1: 0.8842 - val_accuracy: 0.8553 - val_loss: 0.3885 - val_precision_1: 0.9021 - val_recall_1: 0.7848 - learning_rate: 2.5000e-06\n",
            "Epoch 45/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step - accuracy: 0.8994 - loss: 0.2515 - precision_1: 0.9113 - recall_1: 0.8760\n",
            "Epoch 45: val_accuracy did not improve from 0.90065\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 504ms/step - accuracy: 0.8994 - loss: 0.2515 - precision_1: 0.9113 - recall_1: 0.8760 - val_accuracy: 0.8337 - val_loss: 0.4789 - val_precision_1: 0.9398 - val_recall_1: 0.6996 - learning_rate: 2.5000e-06\n",
            "Epoch 46/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502ms/step - accuracy: 0.9017 - loss: 0.2517 - precision_1: 0.9107 - recall_1: 0.8819\n",
            "Epoch 46: val_accuracy did not improve from 0.90065\n",
            "\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 508ms/step - accuracy: 0.9016 - loss: 0.2517 - precision_1: 0.9106 - recall_1: 0.8819 - val_accuracy: 0.8877 - val_loss: 0.4072 - val_precision_1: 0.8608 - val_recall_1: 0.9148 - learning_rate: 2.5000e-06\n",
            "Epoch 47/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - accuracy: 0.9011 - loss: 0.2470 - precision_1: 0.9080 - recall_1: 0.8858\n",
            "Epoch 47: val_accuracy did not improve from 0.90065\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 504ms/step - accuracy: 0.9011 - loss: 0.2471 - precision_1: 0.9080 - recall_1: 0.8858 - val_accuracy: 0.8898 - val_loss: 0.3768 - val_precision_1: 0.8675 - val_recall_1: 0.9103 - learning_rate: 1.2500e-06\n",
            "Epoch 48/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - accuracy: 0.9038 - loss: 0.2508 - precision_1: 0.9124 - recall_1: 0.8870\n",
            "Epoch 48: val_accuracy did not improve from 0.90065\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 504ms/step - accuracy: 0.9037 - loss: 0.2508 - precision_1: 0.9124 - recall_1: 0.8870 - val_accuracy: 0.8769 - val_loss: 0.3737 - val_precision_1: 0.9368 - val_recall_1: 0.7982 - learning_rate: 1.2500e-06\n",
            "Epoch 49/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - accuracy: 0.9068 - loss: 0.2407 - precision_1: 0.9160 - recall_1: 0.8879\n",
            "Epoch 49: val_accuracy did not improve from 0.90065\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 514ms/step - accuracy: 0.9068 - loss: 0.2407 - precision_1: 0.9160 - recall_1: 0.8879 - val_accuracy: 0.8898 - val_loss: 0.3258 - val_precision_1: 0.8772 - val_recall_1: 0.8969 - learning_rate: 1.2500e-06\n",
            "Epoch 50/50\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501ms/step - accuracy: 0.9033 - loss: 0.2489 - precision_1: 0.9124 - recall_1: 0.8874\n",
            "Epoch 50: val_accuracy did not improve from 0.90065\n",
            "\u001b[1m302/302\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 506ms/step - accuracy: 0.9033 - loss: 0.2489 - precision_1: 0.9124 - recall_1: 0.8874 - val_accuracy: 0.8898 - val_loss: 0.3049 - val_precision_1: 0.9216 - val_recall_1: 0.8430 - learning_rate: 1.2500e-06\n",
            "Restoring model weights from the end of the best epoch: 50.\n",
            "\n",
            "Training history saved to training_history.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Final Model Evaluation\n",
            "==================================================\n",
            "\n",
            "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 256ms/step - accuracy: 0.8816 - loss: 0.5526 - precision_1: 0.4147 - recall_1: 0.5332\n",
            "Validation Loss: 0.3690\n",
            "Validation Accuracy: 0.9006\n",
            "Validation Precision: 0.8672\n",
            "Validation Recall: 0.9372\n",
            "Validation F1-Score: 0.9009\n",
            "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 425ms/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Bleached       0.94      0.87      0.90       240\n",
            "     Healthy       0.87      0.94      0.90       223\n",
            "\n",
            "    accuracy                           0.90       463\n",
            "   macro avg       0.90      0.90      0.90       463\n",
            "weighted avg       0.90      0.90      0.90       463\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[208  32]\n",
            " [ 14 209]]\n",
            "Confusion matrix saved to outputs/confusion_matrix.png\n",
            "Training history plots saved to outputs/training_history.png\n",
            "\n",
            "Saving model to coral_reef_resnet50_model.pkl...\n",
            "Model saved to coral_reef_resnet50_model.pkl\n",
            "Model architecture saved to coral_reef_model_architecture.json\n",
            "\n",
            "==================================================\n",
            "Generating GradCAM Visualizations\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-445316010.py:425: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  pred_class = int(preds[0] > 0.5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing /content/coral_reef_dataset/Coral Reef Images/valid/Bleached/youtube-816_jpg.rf.3d54489db652e1db5d12d8c3e689aac6.jpg: No such layer: conv5_block3_out. Existing layers are: ['input_layer_1', 'resnet50', 'global_average_pooling2d', 'batch_normalization', 'dense', 'dropout', 'dense_1', 'dropout_1', 'dense_2'].\n",
            "Error processing /content/coral_reef_dataset/Coral Reef Images/valid/Bleached/youtube-901_jpg.rf.e35d9db41c50c029942da5f744ef2772.jpg: No such layer: conv5_block3_out. Existing layers are: ['input_layer_1', 'resnet50', 'global_average_pooling2d', 'batch_normalization', 'dense', 'dropout', 'dense_1', 'dropout_1', 'dense_2'].\n",
            "Error processing /content/coral_reef_dataset/Coral Reef Images/valid/Bleached/youtube-1024_jpg.rf.43ea89de789c53dff14ccc1b810e593a.jpg: No such layer: conv5_block3_out. Existing layers are: ['input_layer_1', 'resnet50', 'global_average_pooling2d', 'batch_normalization', 'dense', 'dropout', 'dense_1', 'dropout_1', 'dense_2'].\n",
            "Error processing /content/coral_reef_dataset/Coral Reef Images/valid/Bleached/youtube-23_jpg.rf.aab82c84e555a471f1ea8ceb83b9d6b7.jpg: No such layer: conv5_block3_out. Existing layers are: ['input_layer_1', 'resnet50', 'global_average_pooling2d', 'batch_normalization', 'dense', 'dropout', 'dense_1', 'dropout_1', 'dense_2'].\n",
            "Error processing /content/coral_reef_dataset/Coral Reef Images/valid/Bleached/youtube-330_jpg.rf.cea75ccfd9868a357837ee634b6c77e6.jpg: No such layer: conv5_block3_out. Existing layers are: ['input_layer_1', 'resnet50', 'global_average_pooling2d', 'batch_normalization', 'dense', 'dropout', 'dense_1', 'dropout_1', 'dense_2'].\n",
            "Error processing /content/coral_reef_dataset/Coral Reef Images/valid/Healthy/frame_10800_jpg.rf.27de702f20311c86fd05a306823a1c20.jpg: No such layer: conv5_block3_out. Existing layers are: ['input_layer_1', 'resnet50', 'global_average_pooling2d', 'batch_normalization', 'dense', 'dropout', 'dense_1', 'dropout_1', 'dense_2'].\n",
            "Error processing /content/coral_reef_dataset/Coral Reef Images/valid/Healthy/frame_29880_jpg.rf.2677fc6e400546119cdef8abb0dda23f.jpg: No such layer: conv5_block3_out. Existing layers are: ['input_layer_1', 'resnet50', 'global_average_pooling2d', 'batch_normalization', 'dense', 'dropout', 'dense_1', 'dropout_1', 'dense_2'].\n",
            "Error processing /content/coral_reef_dataset/Coral Reef Images/valid/Healthy/youtube-1120_jpg.rf.efd82365d61da9eeb9305600b8cb5700.jpg: No such layer: conv5_block3_out. Existing layers are: ['input_layer_1', 'resnet50', 'global_average_pooling2d', 'batch_normalization', 'dense', 'dropout', 'dense_1', 'dropout_1', 'dense_2'].\n",
            "Error processing /content/coral_reef_dataset/Coral Reef Images/valid/Healthy/frame_42180_jpg.rf.7066b61a9f14fe294f76f1faceea9280.jpg: No such layer: conv5_block3_out. Existing layers are: ['input_layer_1', 'resnet50', 'global_average_pooling2d', 'batch_normalization', 'dense', 'dropout', 'dense_1', 'dropout_1', 'dense_2'].\n",
            "Error processing /content/coral_reef_dataset/Coral Reef Images/valid/Healthy/frame_20340_jpg.rf.40717f7b809707bb5fb84ee7e17aff54.jpg: No such layer: conv5_block3_out. Existing layers are: ['input_layer_1', 'resnet50', 'global_average_pooling2d', 'batch_normalization', 'dense', 'dropout', 'dense_1', 'dropout_1', 'dense_2'].\n",
            "\n",
            "GradCAM visualizations saved to 'gradcam_visualizations/' directory\n",
            "\n",
            "==================================================\n",
            "Training Complete!\n",
            "==================================================\n",
            "\n",
            "Saved files:\n",
            "  - Model (.h5): coral_reef_resnet50_model.h5\n",
            "  - Model (.pkl): coral_reef_resnet50_model.pkl\n",
            "  - Training history: training_history.pkl\n",
            "  - Class indices: class_indices.pkl\n",
            "  - Model architecture: coral_reef_model_architecture.json\n",
            "  - Final metrics: final_metrics.json\n",
            "  - Confusion matrix: outputs/confusion_matrix.png\n",
            "  - Training plots: outputs/training_history.png\n",
            "  - GradCAM visualizations: gradcam_visualizations/\n",
            "\n",
            "==================================================\n",
            "Model Performance Summary\n",
            "==================================================\n",
            "Accuracy:  90.06%\n",
            "Precision: 86.72%\n",
            "Recall:    93.72%\n",
            "F1-Score:  90.09%\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import json\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Define constants\n",
        "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "LEARNING_RATE = 0.0001\n",
        "\n",
        "# Define paths\n",
        "train_dir = '/content/coral_reef_dataset/Coral Reef Images/train'\n",
        "validation_dir = '/content/coral_reef_dataset/Coral Reef Images/valid'\n",
        "model_save_path = 'coral_reef_resnet50_model.h5'\n",
        "model_pkl_path = 'coral_reef_resnet50_model.pkl'\n",
        "history_pkl_path = 'training_history.pkl'\n",
        "\n",
        "# Create directory for saving outputs\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "os.makedirs('gradcam_visualizations', exist_ok=True)\n",
        "\n",
        "# Data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load data generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Get class names\n",
        "class_names = list(train_generator.class_indices.keys())\n",
        "print(f\"Classes: {class_names}\")\n",
        "print(f\"Class indices: {train_generator.class_indices}\")\n",
        "\n",
        "# Save class indices\n",
        "with open('class_indices.pkl', 'wb') as f:\n",
        "    pickle.dump(train_generator.class_indices, f)\n",
        "\n",
        "# Create ResNet50 model\n",
        "def create_resnet50_model(num_classes=1):\n",
        "    \"\"\"\n",
        "    Create a ResNet50 model for binary classification\n",
        "    \"\"\"\n",
        "    # Load pre-trained ResNet50\n",
        "    base_model = ResNet50(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)\n",
        "    )\n",
        "\n",
        "    # Freeze base model layers initially\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Build the model\n",
        "    inputs = layers.Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model, base_model\n",
        "\n",
        "# Create the model\n",
        "print(\"Creating ResNet50 model...\")\n",
        "model, base_model = create_resnet50_model()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
        ")\n",
        "\n",
        "# Print model summary\n",
        "print(\"\\nModel Summary:\")\n",
        "model.summary()\n",
        "\n",
        "# Define callbacks\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        model_save_path,\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        mode='max',\n",
        "        verbose=1\n",
        "    ),\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "# Train the model (Phase 1: Frozen base model)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Phase 1: Training with frozen base model\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "history_phase1 = model.fit(\n",
        "    train_generator,\n",
        "    epochs=15,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fine-tuning (Phase 2: Unfreeze some layers)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Phase 2: Fine-tuning - Unfreezing top layers\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "# Unfreeze the base model\n",
        "base_model.trainable = True\n",
        "\n",
        "# Freeze all layers except the last 50\n",
        "for layer in base_model.layers[:-50]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Recompile with a lower learning rate\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE/10),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
        ")\n",
        "\n",
        "# Continue training\n",
        "history_phase2 = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=callbacks,\n",
        "    initial_epoch=history_phase1.epoch[-1],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Combine training histories\n",
        "combined_history = {\n",
        "    'accuracy': history_phase1.history['accuracy'] + history_phase2.history['accuracy'],\n",
        "    'val_accuracy': history_phase1.history['val_accuracy'] + history_phase2.history['val_accuracy'],\n",
        "    'loss': history_phase1.history['loss'] + history_phase2.history['loss'],\n",
        "    'val_loss': history_phase1.history['val_loss'] + history_phase2.history['val_loss'],\n",
        "    'precision': history_phase1.history['precision'] + history_phase2.history['precision_1'],\n",
        "    'val_precision': history_phase1.history['val_precision'] + history_phase2.history['val_precision_1'],\n",
        "    'recall': history_phase1.history['recall'] + history_phase2.history['recall_1'],\n",
        "    'val_recall': history_phase1.history['val_recall'] + history_phase2.history['val_recall_1']\n",
        "}\n",
        "\n",
        "# Save training history\n",
        "with open(history_pkl_path, 'wb') as f:\n",
        "    pickle.dump(combined_history, f)\n",
        "\n",
        "print(f\"\\nTraining history saved to {history_pkl_path}\")\n",
        "\n",
        "# Load best model\n",
        "model = keras.models.load_model(model_save_path)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Final Model Evaluation\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "loss, accuracy, precision, recall = model.evaluate(validation_generator)\n",
        "f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "print(f\"Validation Loss: {loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Validation Precision: {precision:.4f}\")\n",
        "print(f\"Validation Recall: {recall:.4f}\")\n",
        "print(f\"Validation F1-Score: {f1_score:.4f}\")\n",
        "\n",
        "# Generate predictions\n",
        "validation_generator.reset()\n",
        "y_true = validation_generator.classes\n",
        "y_pred_probs = model.predict(validation_generator, verbose=1)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"Confusion matrix saved to outputs/confusion_matrix.png\")\n",
        "\n",
        "# Plot training history\n",
        "def plot_training_history(history, save_path='outputs/training_history.png'):\n",
        "    \"\"\"Plot training and validation metrics\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # Accuracy\n",
        "    axes[0, 0].plot(history['accuracy'], label='Train Accuracy')\n",
        "    axes[0, 0].plot(history['val_accuracy'], label='Val Accuracy')\n",
        "    axes[0, 0].set_title('Model Accuracy')\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Accuracy')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True)\n",
        "\n",
        "    # Loss\n",
        "    axes[0, 1].plot(history['loss'], label='Train Loss')\n",
        "    axes[0, 1].plot(history['val_loss'], label='Val Loss')\n",
        "    axes[0, 1].set_title('Model Loss')\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('Loss')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True)\n",
        "\n",
        "    # Precision\n",
        "    axes[1, 0].plot(history['precision'], label='Train Precision')\n",
        "    axes[1, 0].plot(history['val_precision'], label='Val Precision')\n",
        "    axes[1, 0].set_title('Model Precision')\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('Precision')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True)\n",
        "\n",
        "    # Recall\n",
        "    axes[1, 1].plot(history['recall'], label='Train Recall')\n",
        "    axes[1, 1].plot(history['val_recall'], label='Val Recall')\n",
        "    axes[1, 1].set_title('Model Recall')\n",
        "    axes[1, 1].set_xlabel('Epoch')\n",
        "    axes[1, 1].set_ylabel('Recall')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Training history plots saved to {save_path}\")\n",
        "\n",
        "plot_training_history(combined_history)\n",
        "\n",
        "# Save model to pickle file\n",
        "print(f\"\\nSaving model to {model_pkl_path}...\")\n",
        "with open(model_pkl_path, 'wb') as f:\n",
        "    pickle.dump({\n",
        "        'model_architecture': model.to_json(),\n",
        "        'model_weights': model.get_weights(),\n",
        "        'class_indices': train_generator.class_indices,\n",
        "        'input_shape': (IMG_WIDTH, IMG_HEIGHT, 3)\n",
        "    }, f)\n",
        "print(f\"Model saved to {model_pkl_path}\")\n",
        "\n",
        "# Save model architecture to JSON\n",
        "model_json = model.to_json()\n",
        "with open('coral_reef_model_architecture.json', 'w') as json_file:\n",
        "    json_file.write(model_json)\n",
        "print(\"Model architecture saved to coral_reef_model_architecture.json\")\n",
        "\n",
        "# =====================================================\n",
        "# GradCAM Implementation\n",
        "# =====================================================\n",
        "\n",
        "def get_img_array(img_path, size=(IMG_WIDTH, IMG_HEIGHT)):\n",
        "    \"\"\"Load and preprocess image\"\"\"\n",
        "    img = load_img(img_path, target_size=size)\n",
        "    array = img_to_array(img)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    array = array / 255.0\n",
        "    return array\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    \"\"\"\n",
        "    Generate GradCAM heatmap\n",
        "    \"\"\"\n",
        "    # Create a model that maps the input image to the activations of the last conv layer\n",
        "    grad_model = keras.models.Model(\n",
        "        [model.inputs],\n",
        "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    # Compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    # Gradient of the output neuron with regard to the output feature map\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    # Vector of mean intensity of the gradient over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # Multiply each channel by \"how important this channel is\"\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # Normalize the heatmap\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def save_and_display_gradcam(img_path, heatmap, output_path, alpha=0.4):\n",
        "    \"\"\"\n",
        "    Overlay GradCAM heatmap on original image and save\n",
        "    \"\"\"\n",
        "    # Load the original image\n",
        "    img = load_img(img_path)\n",
        "    img = img_to_array(img)\n",
        "\n",
        "    # Rescale heatmap to range 0-255\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    # Use jet colormap to colorize heatmap\n",
        "    jet = plt.cm.get_cmap(\"jet\")\n",
        "\n",
        "    # Use RGB values of the colormap\n",
        "    jet_colors = jet(np.arange(256))[:, :3]\n",
        "    jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "    # Create an image with RGB colorized heatmap\n",
        "    jet_heatmap = keras.utils.array_to_img(jet_heatmap)\n",
        "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "    jet_heatmap = keras.utils.img_to_array(jet_heatmap)\n",
        "\n",
        "    # Superimpose the heatmap on original image\n",
        "    superimposed_img = jet_heatmap * alpha + img\n",
        "    superimposed_img = keras.utils.array_to_img(superimposed_img)\n",
        "\n",
        "    # Create a figure with subplots\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "    # Original image\n",
        "    axes[0].imshow(keras.utils.array_to_img(img))\n",
        "    axes[0].set_title('Original Image', fontsize=14, fontweight='bold')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Heatmap\n",
        "    axes[1].imshow(jet_heatmap / 255.0)\n",
        "    axes[1].set_title('GradCAM Heatmap', fontsize=14, fontweight='bold')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    # Superimposed\n",
        "    axes[2].imshow(superimposed_img)\n",
        "    axes[2].set_title('GradCAM Overlay', fontsize=14, fontweight='bold')\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    return superimposed_img\n",
        "\n",
        "def generate_gradcam_for_image(img_path, model, class_indices, output_dir='gradcam_visualizations'):\n",
        "    \"\"\"\n",
        "    Generate GradCAM visualization for a single image\n",
        "    \"\"\"\n",
        "    # Get the name of the last convolutional layer in ResNet50\n",
        "    last_conv_layer_name = 'conv5_block3_out'  # Last conv layer in ResNet50\n",
        "\n",
        "    # Prepare image\n",
        "    img_array = get_img_array(img_path)\n",
        "\n",
        "    # Make prediction\n",
        "    preds = model.predict(img_array, verbose=0)\n",
        "    pred_class = int(preds[0] > 0.5)\n",
        "    confidence = preds[0][0] if pred_class == 1 else 1 - preds[0][0]\n",
        "\n",
        "    # Get class names\n",
        "    class_names_dict = {v: k for k, v in class_indices.items()}\n",
        "    predicted_class_name = class_names_dict[pred_class]\n",
        "\n",
        "    # Generate heatmap\n",
        "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "\n",
        "    # Create output filename\n",
        "    img_filename = os.path.basename(img_path)\n",
        "    output_path = os.path.join(output_dir, f'gradcam_{img_filename}')\n",
        "\n",
        "    # Save visualization\n",
        "    save_and_display_gradcam(img_path, heatmap, output_path)\n",
        "\n",
        "    print(f\"GradCAM for {img_filename}:\")\n",
        "    print(f\"  Predicted: {predicted_class_name} (Confidence: {confidence:.2%})\")\n",
        "    print(f\"  Saved to: {output_path}\")\n",
        "\n",
        "    return predicted_class_name, confidence\n",
        "\n",
        "# Generate GradCAM for sample images from validation set\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Generating GradCAM Visualizations\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "# Get sample images from each class\n",
        "sample_images = []\n",
        "for class_name in class_names:\n",
        "    class_dir = os.path.join(validation_dir, class_name)\n",
        "    if os.path.exists(class_dir):\n",
        "        images = [os.path.join(class_dir, img) for img in os.listdir(class_dir)\n",
        "                 if img.lower().endswith(('.png', '.jpg', '.jpeg'))][:5]  # Get 5 samples per class\n",
        "        sample_images.extend(images)\n",
        "\n",
        "# Generate GradCAM for sample images\n",
        "for img_path in sample_images:\n",
        "    try:\n",
        "        generate_gradcam_for_image(img_path, model, train_generator.class_indices)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {img_path}: {e}\")\n",
        "\n",
        "print(f\"\\nGradCAM visualizations saved to 'gradcam_visualizations/' directory\")\n",
        "\n",
        "# =====================================================\n",
        "# Utility function to load saved model from pickle\n",
        "# =====================================================\n",
        "\n",
        "def load_model_from_pickle(pkl_path):\n",
        "    \"\"\"\n",
        "    Load model from pickle file\n",
        "    \"\"\"\n",
        "    with open(pkl_path, 'rb') as f:\n",
        "        model_data = pickle.load(f)\n",
        "\n",
        "    # Reconstruct model\n",
        "    model = keras.models.model_from_json(model_data['model_architecture'])\n",
        "    model.set_weights(model_data['model_weights'])\n",
        "\n",
        "    return model, model_data['class_indices']\n",
        "\n",
        "# Save final metrics\n",
        "final_metrics = {\n",
        "    'accuracy': float(accuracy),\n",
        "    'precision': float(precision),\n",
        "    'recall': float(recall),\n",
        "    'f1_score': float(f1_score),\n",
        "    'loss': float(loss),\n",
        "    'confusion_matrix': cm.tolist(),\n",
        "    'class_names': class_names\n",
        "}\n",
        "\n",
        "with open('final_metrics.json', 'w') as f:\n",
        "    json.dump(final_metrics, f, indent=4)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Training Complete!\")\n",
        "print(\"=\"*50)\n",
        "print(f\"\\nSaved files:\")\n",
        "print(f\"  - Model (.h5): {model_save_path}\")\n",
        "print(f\"  - Model (.pkl): {model_pkl_path}\")\n",
        "print(f\"  - Training history: {history_pkl_path}\")\n",
        "print(f\"  - Class indices: class_indices.pkl\")\n",
        "print(f\"  - Model architecture: coral_reef_model_architecture.json\")\n",
        "print(f\"  - Final metrics: final_metrics.json\")\n",
        "print(f\"  - Confusion matrix: outputs/confusion_matrix.png\")\n",
        "print(f\"  - Training plots: outputs/training_history.png\")\n",
        "print(f\"  - GradCAM visualizations: gradcam_visualizations/\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Model Performance Summary\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy:  {accuracy:.2%}\")\n",
        "print(f\"Precision: {precision:.2%}\")\n",
        "print(f\"Recall:    {recall:.2%}\")\n",
        "print(f\"F1-Score:  {f1_score:.2%}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Gm29TmXdwDgI",
        "outputId": "d2c7127b-5d13-400d-9466-938023359f0a"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_e705aa7a-e5fa-4187-8593-1e4ed2373916\", \"coral_reef_resnet50_model.h5\", 237176160)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"coral_reef_resnet50_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "6TUNqwCnwb8F",
        "outputId": "aead26dc-397d-4bc3-9574-b532cd12bc82"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_1f2ccd81-e697-4dd2-b020-c75c763424d0\", \"coral_reef_resnet50_model.pkl\", 96795527)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"coral_reef_resnet50_model.pkl\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
